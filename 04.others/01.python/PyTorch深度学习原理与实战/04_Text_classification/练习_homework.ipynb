{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/e/e7/集智AI学园首页左上角logo_2017.8.17.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 火炬上的深度学习（下）第二节：机器也懂感情？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 课后练习：使用 LSTM 来判断人名属于哪个国家"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们要使用 PyTorch 搭建一个 LSTM 模型。\n",
    "\n",
    "模型的输入是用ASCII字符表示的姓氏，输出是模型对这个姓氏所属语言的判断。\n",
    "\n",
    "模型的训练数据是来自18种语言的2万条左右的姓氏文本。\n",
    "\n",
    "训练完毕的理想模型可以预测出一个姓氏是属于哪种语言的。并且，我们还可以通过模型的预测结果分析各语言姓氏的相似性。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最终训练好的模型可以像下面那样使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "predict Hinton\n",
    "(-0.47) Scottish\n",
    "(-1.52) English\n",
    "(-3.57) Irish\n",
    "\n",
    "predict.py Schmidhuber\n",
    "(-0.19) German\n",
    "(-2.48) Czech\n",
    "(-2.68) Dutch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理解 LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看到本练习相信你已经对 LSTM 有一定的认识了。\n",
    "\n",
    "如果还不熟悉 LSTM 可以再去看一下张老师讲的[课程](http://campus.swarma.org/gcou=10341)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 处理训练数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在提供的数据文件中，包含在 data/names 目录下的是18个命名规则为\"[Language].txt\"的文本文件，每个文件都包含一些名字，每个名字占一行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "all_filenames = glob.glob('./data/names/*.txt')\n",
    "print(all_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在先让我们解决这个问题：\n",
    "\n",
    "在我们收集的18种语言的名字中，中文、日文、韩文等名字都已经转化为音译的字母。这样做是因为有些语言的名字并不能用普通的ASCII英文字符来表示，比如“Ślusàrski”，这些不一样的字母会增加神经网络的“困惑”，影响其训练效果。所以我们得首先把这些特别的字母转换成普通的ASCII字符（即26个英文字母）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import string\n",
    "\n",
    "# 使用26个英文字母大小写再加上.,;这三个字符\n",
    "# 建立字母表，并取其长度\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "\n",
    "# 将Unicode字符串转换为纯ASCII\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "print(unicode_to_ascii('Ślusàrski'))\n",
    "print('all_letters:', all_letters)\n",
    "print('all_letters:', len(all_letters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后再建立 readLines 方法，用于从文件中一行一行的将姓氏读取出来。\n",
    "\n",
    "以18种语言为索引，将读取出的姓氏各自存储在名为 `category_lines` 的字典中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 构建category_lines字典，名字和每种语言对应的列表\n",
    "category_lines = {}\n",
    "all_categories = []\n",
    "\n",
    "# 按行读取出名字并转换成纯ASCII\n",
    "def readLines(filename):\n",
    "    lines = open(filename).read().strip().split('\\n')\n",
    "    return [unicode_to_ascii(line) for line in lines]\n",
    "\n",
    "for filename in all_filenames:\n",
    "    # 取出每个文件的文件名（语言名）\n",
    "    category = filename.split('/')[-1].split('.')[0]\n",
    "    # 将语言名加入到all_categories列表\n",
    "    all_categories.append(category)\n",
    "    # 取出所有的姓氏lines\n",
    "    lines = readLines(filename)\n",
    "    # 将所有姓氏以语言为索引，加入到字典中\n",
    "    category_lines[category] = lines\n",
    "\n",
    "n_categories = len(all_categories)\n",
    "\n",
    "print('all_categories:', all_categories)\n",
    "print('n_categories =', n_categories)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`all_categories` 中包含18中语言的姓氏。\n",
    "\n",
    "`category_lines` 中以18中语言为索引，存储了所有的姓氏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(category_lines['Italian'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们来统计下数据中所有姓氏的个数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_line_num = 0\n",
    "for key in category_lines:\n",
    "    all_line_num += len(category_lines[key])\n",
    "print(all_line_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先导入程序所需要的程序包\n",
    "\n",
    "#PyTorch用的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "\n",
    "\n",
    "#绘图、计算用的程序包\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们再编写一个方法用于快速地获得一个训练实例（即一个名字以及它所属的语言）：\n",
    "\n",
    "其中 line_index 中保存的是选择的姓氏中的字母的索引，这个需要你去实现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_training_pair():   \n",
    "    # 随机选择一种语言\n",
    "    category = random.choice(all_categories)\n",
    "    # 从语言中随机选择一个姓氏\n",
    "    line = random.choice(category_lines[category])\n",
    "    # 我们将姓氏和语言都转化为索引\n",
    "    category_index = all_categories.index(category)\n",
    "    \n",
    "    line_index = []\n",
    "    # 你需要把 line 中字母的索引加入到line_index 中\n",
    "    # Todo:\n",
    "    \n",
    "    \n",
    "    return category, line, category_index, line_index\n",
    "\n",
    "# 测试一下上面的函数方法\n",
    "for i in range(5):\n",
    "    category, line, category_index, line_index = random_training_pair()\n",
    "    print('category =', category, '/ line =', line)\n",
    "    print('category =', category_index, '/ line =', line_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们再建立一个用户转化模型输出的辅助函数。\n",
    "\n",
    "它可以把网络的输出（1 x 18的张量）转化成“最可能的语言类别”，这就需要找到18列数据中哪个概率值最大。\n",
    "\n",
    "我们可以使用 `Tensor.topk` 方法来得到数据中最大值位置的索引。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_from_output(output):\n",
    "    # 1 代表在‘列’间找到最大\n",
    "    # top_n 是具体的值\n",
    "    # top_i 是位置索引\n",
    "    # 注意这里 top_n 和 top_i 都是1x1的张量\n",
    "    # output.data 取出张量数据\n",
    "    top_n, top_i = output.data.topk(1) \n",
    "    # 从张量中取出索引值\n",
    "    category_i = top_i[0][0]\n",
    "    # 返回语言类别名和位置索引\n",
    "    return all_categories[category_i], category_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编写 LSTM 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在是建立 LSTM 模型的时候了。\n",
    "\n",
    "我在模型中设置了一些空缺，**你需要编写空缺处的代码。**\n",
    "\n",
    "如果遇到问题，可以参考[课程](http://campus.swarma.org/gcou=10341)中的代码讲解哦！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_layers=1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # LSTM的构造如下：\n",
    "        # 一个embedding层，将输入的任意一个单词（list）映射为一个向量（向量的维度与隐含层有关系？）\n",
    "        self.embedding = \n",
    "        # 然后是一个LSTM隐含层，共有hidden_size个LSTM神经元，并且它可以根据n_layers设置层数\n",
    "        self.lstm = \n",
    "        # 接着是一个全链接层，外接一个softmax输出\n",
    "        self.fc = \n",
    "        self.logsoftmax = nn.LogSoftmax()\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        #首先根据输入input，进行词向量嵌入\n",
    "        embedded = \n",
    "        \n",
    "        # 这里需要注意！\n",
    "        # PyTorch设计的LSTM层有一个特别别扭的地方是，输入张量的第一个维度需要是时间步，\n",
    "        # 第二个维度才是batch_size，所以需要对embedded变形\n",
    "        # 因为此次没有采用batch，所以batch_size为1\n",
    "        # 变形的维度应该是（input_list_size, batch_size, hidden_size）\n",
    "        embedded = embedded.view(, , )\n",
    "    \n",
    "        # 调用PyTorch自带的LSTM层函数，注意有两个输入，一个是输入层的输入，另一个是隐含层自身的输入\n",
    "        # 输出output是所有步的隐含神经元的输出结果，hidden是隐含层在最后一个时间步的状态。\n",
    "        # 注意hidden是一个tuple，包含了最后时间步的隐含层神经元的输出，以及每一个隐含层神经元的cell的状态\n",
    "        \n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        \n",
    "        #我们要把最后一个时间步的隐含神经元输出结果拿出来，送给全连接层\n",
    "        output = output[-1,...]\n",
    "\n",
    "        #全链接层\n",
    "        out = self.fc(output)\n",
    "        # softmax\n",
    "        out = self.logsoftmax(out)\n",
    "        return out\n",
    "\n",
    "    def initHidden(self):\n",
    "        # 对隐单元的初始化\n",
    "        # 对引单元输出的初始化，全0.\n",
    "        # 注意hidden和cell的维度都是layers,batch_size,hidden_size\n",
    "        hidden = torch.zeros(self.n_layers, 1, self.hidden_size)\n",
    "        # 对隐单元内部的状态cell的初始化，全0\n",
    "        cell = torch.zeros(self.n_layers, 1, self.hidden_size)\n",
    "        return (hidden, cell)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每次训练模型的时候，我的心里都是有点小激动的！\n",
    "\n",
    "我同样在训练程序中预留了一些空位，**你要编写空余位置的程序**，训练才可以正常进行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "# 开始训练LSTM网络\n",
    "n_epochs = 100000\n",
    "\n",
    "# 构造一个LSTM网络的实例\n",
    "lstm = LSTMNetwork(n_letters, 10, n_categories, 2)\n",
    "\n",
    "#定义损失函数\n",
    "cost = torch.nn.NLLLoss()\n",
    "\n",
    "#定义优化器,\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr = 0.001)\n",
    "records = []\n",
    "\n",
    "# 用于计算训练时间的函数\n",
    "def time_since(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# 开始训练，一共5个epoch，否则容易过拟合\n",
    "for epoch in range(5):\n",
    "    losses = []\n",
    "    #每次随机选择数据进行训练，每个 EPOCH 训练“所有名字个数”次。\n",
    "    for i in range(all_line_num):\n",
    "        category, line, y, x = random_training_pair()\n",
    "        x = torch.tensor(x, dtype = torch.long)\n",
    "        y = torch.tensor(np.array([y]), dtype = torch.long)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Step1:初始化LSTM隐含层单元的状态\n",
    "        hidden = \n",
    "        \n",
    "        # Step2:让LSTM开始做运算，注意，不需要手工编写对时间步的循环，而是直接交给PyTorch的LSTM层。\n",
    "        # 它自动会根据数据的维度计算若干时间步\n",
    "        output = \n",
    "        \n",
    "        # Step3:计算损失\n",
    "        loss = \n",
    "        losses.append(loss.data.numpy()[0])\n",
    "        \n",
    "        #反向传播\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #每隔3000步，跑一次校验集，并打印结果\n",
    "        if i % 3000 == 0:\n",
    "            # 判断模型的预测是否正确\n",
    "            guess, guess_i = category_from_output(output)\n",
    "            correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "            # 计算训练进度\n",
    "            training_process = (all_line_num * epoch + i) / (all_line_num * 5) * 100\n",
    "            training_process = '%.2f' % training_process\n",
    "            print('第{}轮，训练损失：{:.2f}，训练进度：{}%，（{}），名字：{}，预测国家：{}，正确？{}'\\\n",
    "                .format(epoch, np.mean(losses), float(training_process), time_since(start), line, guess, correct))\n",
    "            records.append([np.mean(losses)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i[0] for i in records]\n",
    "plt.plot(a, label = 'Train Loss')\n",
    "plt.xlabel('Steps')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 通过姓氏分析语言的相似性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "激动人心的时刻到了！\n",
    "\n",
    "下面将使用10000条数据评估训练好的模型，并根据评估的结果绘制图形，从图形中我们可以发现哪些语言的姓氏是相似的！\n",
    "\n",
    "**你需要自行编写 evaluate 函数的内容。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# 建立一个（18 x 18）的方阵张量\n",
    "# 用于保存神经网络做出的预测结果\n",
    "confusion = torch.zeros(n_categories, n_categories)\n",
    "# 用于评估的模型的测试次数\n",
    "n_confusion = 10000\n",
    "\n",
    "\n",
    "# 评估用方法 传进去一个名字，给出预测结果\n",
    "# 可以观察到这个方法的实现与 train 方法前半部分类似\n",
    "# 其实它就是去掉反向传播的 train 方法\n",
    "def evaluate(line_list):\n",
    "    # 调用模型前应该先初始化模型的隐含层\n",
    "    hidden = \n",
    "    # 别忘了将输入的list转化为torch.Variable\n",
    "    line_variable = \n",
    "    # 调用模型\n",
    "    output = lstm(line_variable, hidden)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# 循环一万次\n",
    "for i in range(n_confusion):\n",
    "    # 随机选择测试数据，包括姓氏以及所属语言\n",
    "    category, line, category_index, line_list = random_training_pair()\n",
    "    # 取得预测结果\n",
    "    output = evaluate(line_list)\n",
    "    \n",
    "    # 取得预测结果的语言和索引\n",
    "    guess, guess_i = category_from_output(output)\n",
    "    \n",
    "    # 以姓氏实际的所属语言为行\n",
    "    # 以模型预测的所属语言为列\n",
    "    # 在方阵的特定位置增加1\n",
    "\n",
    "    confusion[category_index][guess_i] += 1\n",
    "\n",
    "# 数据归一化\n",
    "for i in range(n_categories):\n",
    "    confusion[i] = confusion[i] / confusion[i].sum()\n",
    "\n",
    "# 设置一个图表\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "# 将 confusion 方阵数据传入\n",
    "cax = ax.matshow(confusion.numpy())\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# 设置图表两边的语言类别名称\n",
    "ax.set_xticklabels([''] + all_categories, rotation=90)\n",
    "ax.set_yticklabels([''] + all_categories)\n",
    "\n",
    "ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先看行再看列，行标签代表姓氏实际所属语言，列标签代表模型预测姓氏所属语言。\n",
    "\n",
    "色块颜色越亮代表预测次数越高。整张图表中对角线最亮，说明模型对大部分数据的预测都是准确的。\n",
    "\n",
    "但是！我们要观察的是预测错误的情况，即对角线以外的亮色块！\n",
    "\n",
    "先看 English 这一行，可以看到 English 对角线上的色块很暗啊，说明模型对英文姓氏的预测很差。同时，除对角线方块外，在 English 这一行可以观察到很多浅色方块，它们分别是：Czech（捷克语）、French（法语）、German（德语）、Irish（爱尔兰语）、Scottish（苏格兰语）。这些国家文化相近，姓氏相似，所以模型没能做到非常好的区分。\n",
    "\n",
    "而东方国家，让我们观察中国这一行，可以看到中国、韩国、越南（Vietnamese）的姓氏有一定的相似度，这与国家间的文化是相符的。\n",
    "\n",
    "另外还有西班牙和葡萄牙，这两个国家的姓氏也有些相似。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将模型封装的更易用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们重新把焦点转移到训练的模型上来。\n",
    "\n",
    "下面我要编写一个函数将训练的模型封装起来，以便于调用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# predict函数\n",
    "# 第一个参数为要进行预测的姓氏\n",
    "# 第二个参数为预测最大可能所属语言的数量\n",
    "def predict(input_line, n_predictions=3):\n",
    "    # 首先将用户输入的名字打印出来\n",
    "    print('\\n> %s' % input_line)\n",
    "    # 将用户输入的字符串转化为索引列表\n",
    "    input_line = list(map(lambda x: all_letters.find(x), input_line))\n",
    "    # 将用户输入的名字传入模型中进行预测\n",
    "    output = evaluate(input_line)\n",
    "\n",
    "    # 获得概率最大的n_predictions个语言类别\n",
    "    topv, topi = output.data.topk(n_predictions, 1, True)\n",
    "    # topv中保存着概率值\n",
    "    # topi中保存着位置索引\n",
    "\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(n_predictions):\n",
    "        value = topv[0][i]\n",
    "        category_index = topi[0][i]\n",
    "        # 将预测概率最大的三种语言类别格式化后打印出来\n",
    "        print('(%.2f) %s' % (value, all_categories[category_index]))\n",
    "        # 将它们存储到 predictions 中\n",
    "        predictions.append([value, all_categories[category_index]])\n",
    "\n",
    "predict('Dovesky')\n",
    "predict('Jackson')\n",
    "predict('Satoshi')\n",
    "predict('Han')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到这里本次练习就结束了，希望本次练习可以加深你对 LSTM 的认识。如果在练习中遇到了问题，可以在 火炬上的深度学习 课程讨论群 中进行提问，对不模型有不明白的地方，可以再重复学习下课程视频中的讲解。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://wiki.swarma.net/images/c/ca/AI学园.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
