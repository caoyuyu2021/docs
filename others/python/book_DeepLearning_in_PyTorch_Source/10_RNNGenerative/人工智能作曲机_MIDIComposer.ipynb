{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经莫扎特——MIDI音乐的学习与生成\n",
    "\n",
    "在这节课中，我们学习了如何通过人工神经网络学习一个MIDI音乐，并记忆中音符时间序列中的模式，并生成一首音乐\n",
    "\n",
    "首先，我们要学习如何解析一个MIDI音乐，将它读如进来；其次，我们用处理后的MIDI序列数据训练一个LSTM网络，并让它预测下一个音符；\n",
    "\n",
    "最后，我们用训练好的LSTM生成MIDI音乐\n",
    "\n",
    "本程序改造自\n",
    "\n",
    "本文件是集智学园http://campus.swarma.org 出品的“火炬上的深度学习”第VI课的配套源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必须的依赖包\n",
    "\n",
    "# 与PyTorch相关的包\n",
    "import torch\n",
    "import torch.utils.data as DataSet\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# 导入midi音乐处理的包\n",
    "from mido import MidiFile, MidiTrack, Message\n",
    "\n",
    "# 导入计算与绘图必须的包\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一、导入MIDI文件，并处理成标准形式 \n",
    "\n",
    "首先，我们从MIDI文件中提取出消息（Message）序列，一个消息包括：音符（note）、速度（velocity）与时间（time，距离上一个音符的时间长度）\n",
    "\n",
    "其次，我们要将每一个消息进行编码，根据音符、速度、时间的取值范围，我们分别用长度为89、128与11的one-hot编码得到一个01向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 从硬盘读取MIDI文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从硬盘中读入MIDI音乐文件\n",
    "#mid = MidiFile('./music/allegroconspirito.mid') # a Mozart piece\n",
    "mid = MidiFile('./music/krebs.mid') # a Mozart piece\n",
    "\n",
    "notes = []\n",
    "\n",
    "time = float(0)\n",
    "prev = float(0)\n",
    "\n",
    "original = [] # original记载了原始message数据，以便后面的比较\n",
    "\n",
    "# 对MIDI文件中所有的消息进行循环\n",
    "for msg in mid:\n",
    "    # 时间的单位是秒，而不是帧\n",
    "    time += msg.time\n",
    "    \n",
    "    # 如果当前消息不是描述信息\n",
    "    if not msg.is_meta:\n",
    "        # 仅提炼第一个channel的音符\n",
    "        if msg.channel == 0:\n",
    "            # 如果当前音符为打开的\n",
    "            if msg.type == 'note_on':\n",
    "                # 获得消息中的信息（编码在字节中）\n",
    "                note = msg.bytes() \n",
    "                # 我们仅对音符信息感兴趣. 音符消息按如下形式记录 [type, note, velocity]\n",
    "                note = note[1:3] #操作完这一步后，note[0]存音符，note[1]存速度（力度）\n",
    "                # note[2]存据上一个message的时间间隔\n",
    "                note.append(time - prev)\n",
    "                prev = time\n",
    "                # 将音符添加到列表notes中\n",
    "                notes.append(note)\n",
    "                # 在原始列表中保留这些音符\n",
    "                original.append([i for i in note])\n",
    "\n",
    "# 绘制每一个分量的直方图，方便看出每一个量的取值范围\n",
    "plt.figure()\n",
    "plt.hist([i[0] for i in notes])\n",
    "plt.title('Note')\n",
    "plt.figure()\n",
    "plt.hist([i[1] for i in notes])\n",
    "plt.title('Velocity')\n",
    "plt.figure()\n",
    "plt.hist([i[2] for i in notes])\n",
    "plt.title('Time')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 将每一个Message进行编码"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始的数据是形如(78, 0, 0.0108)这样的三元组\n",
    "\n",
    "编码后的数据格式为：(00...010..., 100..., 0100...)这样的三个one-hot向量，第一个向量长度89，第二个128，第三个11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note和velocity都可以看作是类型变量\n",
    "# time为float，我们按照区间将其也化成离散的类型变量\n",
    "# 首先，我们找到time变量的取值区间，并进行划分。由于大量msg的time为0，因此我们把0归为了一个特别的类\n",
    "intervals = 10\n",
    "values = np.array([i[2] for i in notes])\n",
    "max_t = np.amax(values) #区间中的最大值\n",
    "min_t = np.amin(values[values > 0]) #区间中的最小值\n",
    "interval = 1.0 * (max_t - min_t) / intervals\n",
    "\n",
    "# 接下来，我们将每一个message编码成三个one-hot向量，将这三个向量合并到一起就构成了slot向量\n",
    "dataset = []\n",
    "for note in notes:\n",
    "    slot = np.zeros(89 + 128 + 12)\n",
    "    \n",
    "    #由于note是介于24-112之间的，因此减24\n",
    "    ind1 = note[0]-24\n",
    "    ind2 = note[1]\n",
    "    # 由于message中有大量的time=0的情况，因此我们将0分为单独的一类，其他的都是按照区间划分\n",
    "    ind3 = int((note[2] - min_t) / interval + 1) if note[2] > 0 else 0\n",
    "    slot[ind1] = 1\n",
    "    slot[89 + ind2] = 1\n",
    "    slot[89 + 128 + ind3] = 1\n",
    "    # 将处理后得到的slot数组加入到dataset中\n",
    "    dataset.append(slot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.生成训练集和校验集，装进数据加载器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将整个音符三元组（note，velocity，time）序列按照31位长度的滑动窗口切分成了len(dataset)-n_prev组\n",
    "\n",
    "每一组的前30位作为输入，最后一位作为输出形成了训练数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成训练集和校验集\n",
    "X = []\n",
    "Y = []\n",
    "# 首先，按照预测的模式，我们将原始数据生成一对一对的训练数据\n",
    "n_prev = 30 # 滑动窗口长度为30\n",
    "\n",
    "# 对数据中的所有数据进行循环\n",
    "for i in range(len(dataset)-n_prev):\n",
    "    # 往后取n_prev个note作为输入属性\n",
    "    x = dataset[i:i+n_prev]\n",
    "    # 将第n_prev+1个note（编码前）作为目标属性\n",
    "    y = notes[i+n_prev]\n",
    "    # 注意time要转化成类别的形式\n",
    "    ind3 = int((y[2] - min_t) / interval + 1) if y[2] > 0 else 0\n",
    "    y[2] = ind3\n",
    "    \n",
    "    # 将X和Y加入到数据集中\n",
    "    X.append(x)\n",
    "    Y.append(y)\n",
    "    \n",
    "# 将数据集中的前n_prev个音符作为种子，用于生成音乐的时候用\n",
    "seed = dataset[0:n_prev]\n",
    "\n",
    "# 对所有数据顺序打乱重排\n",
    "idx = np.random.permutation(range(len(X)))\n",
    "# 形成训练与校验数据集列表\n",
    "X = [X[i] for i in idx]\n",
    "Y = [Y[i] for i in idx]\n",
    "\n",
    "# 从中切分1/10的数据出来放入校验集\n",
    "validX = X[: len(X) // 10]\n",
    "X = X[len(X) // 10 :]\n",
    "validY = Y[: len(Y) // 10]\n",
    "Y = Y[len(Y) // 10 :]\n",
    "\n",
    "# 将列表再转化为dataset，并用dataloader来加载数据\n",
    "# dataloader是PyTorch开发采用的一套管理数据的方法。通常数据的存储放在dataset中，而对数据的调用则是通过data loader完成的\n",
    "# 同时，在进行预处理的时候，系统已经自动将数据打包成撮（batch），每次调用，我们都提取一整个撮出来（包含多条记录）\n",
    "# 从dataloader中吐出的每一个元素都是一个(x,y)元组，其中x为输入的张量，y为标签。x和y的第一个维度都是batch_size大小。\n",
    "\n",
    "batch_size = 30 #一撮包含30个数据记录，这个数字越大，系统在训练的时候，每一个周期处理的数据就越多，这样处理越快，但总的数据量会减少\n",
    "\n",
    "# 形成训练集\n",
    "train_ds = DataSet.TensorDataset(torch.FloatTensor(np.array(X, dtype = float)), torch.LongTensor(np.array(Y)))\n",
    "# 形成数据加载器\n",
    "train_loader = DataSet.DataLoader(train_ds, batch_size = batch_size, shuffle = True, num_workers=4)\n",
    "\n",
    "\n",
    "# 校验数据\n",
    "valid_ds = DataSet.TensorDataset(torch.FloatTensor(np.array(validX, dtype = float)), torch.LongTensor(np.array(validY)))\n",
    "valid_loader = DataSet.DataLoader(valid_ds, batch_size = batch_size, shuffle = True, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二、定义一个LSTM网络\n",
    "\n",
    "该网络特殊的地方在于它的输出，对于每一个样本，它会输出三个变量x,y,z，它们分别是一个归一化的概率向量\n",
    "\n",
    "分别用来预测类型化了的note、velocity和time\n",
    "\n",
    "在网络中我们对lstm的输出结果进行dropout的操作，所谓的dropout就是指在训练的截断，系统会随机删除掉一些神经元，\n",
    "，而在测试阶段则不会删掉神经元，这样使得模型给出正确的输出会更加困难，从避免了过拟合现象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class LSTMNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_size, n_layers=1):\n",
    "        super(LSTMNetwork, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.hidden_size = hidden_size\n",
    "        self.out_size = out_size\n",
    "        # 一层LSTM单元\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, n_layers, batch_first = True)\n",
    "        # 一个Dropout部件，以0.2的概率Dropout\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        # 一个全链接层\n",
    "        self.fc = nn.Linear(hidden_size, out_size)\n",
    "        # 对数Softmax层\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "\n",
    "    def forward(self, input, hidden=None):\n",
    "        # 神经网络的每一步运算\n",
    "\n",
    "        hhh1 = hidden[0] #读如隐含层的初始信息\n",
    "        \n",
    "        # 完成一步LSTM运算\n",
    "        # input的尺寸为：batch_size , time_step, input_size\n",
    "        output, hhh1 = self.lstm(input, hhh1) #input:batchsize*timestep*3\n",
    "        # 对神经元输出的结果进行dropout\n",
    "        output = self.dropout(output)\n",
    "        # 取出最后一个时刻的隐含层输出值\n",
    "        # output的尺寸为：batch_size, time_step, hidden_size\n",
    "        output = output[:, -1, ...]\n",
    "        # 此时，output的尺寸为：batch_size, hidden_size\n",
    "        # 喂入一个全链接层\n",
    "        out = self.fc(output)\n",
    "        # out的尺寸为：batch_size, output_size\n",
    "\n",
    "        # 将out的最后一个维度分割成三份x, y, z分别对应对note，velocity以及time的预测\n",
    "        \n",
    "        x = self.softmax(out[:, :89])\n",
    "        y = self.softmax(out[:, 89: 89 + 128])\n",
    "        z = self.softmax(out[:, 89 + 128:])\n",
    "        \n",
    "        # x的尺寸为batch_size, 89\n",
    "        # y的尺寸为batch_size, 128\n",
    "        # z的尺寸为batch_size, 11\n",
    "        # 返回x,y,z\n",
    "        return (x,y,z)\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        # 对隐含层单元变量全部初始化为0\n",
    "        # 注意尺寸是： layer_size, batch_size, hidden_size\n",
    "        out = []\n",
    "        hidden1=torch.zeros(1, batch_size, self.hidden_size)\n",
    "        cell1=torch.zeros(1, batch_size, self.hidden_size)\n",
    "        out.append((hidden1, cell1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(outputs, target):\n",
    "    # 为本模型自定义的损失函数，它由三部分组成，每部分都是一个交叉熵损失函数，\n",
    "    # 它们分别对应note、velocity和time的交叉熵\n",
    "    x, y, z = outputs\n",
    "    loss_f = nn.NLLLoss()\n",
    "    loss1 = loss_f(x, target[:, 0])\n",
    "    loss2 = loss_f(y, target[:, 1])\n",
    "    loss3 = loss_f(z, target[:, 2])\n",
    "    return loss1 + loss2 + loss3\n",
    "def rightness(predictions, labels):\n",
    "    \"\"\"计算预测错误率的函数，其中predictions是模型给出的一组预测结果，batch_size行num_classes列的矩阵，labels是数据之中的正确答案\"\"\"\n",
    "    pred = torch.max(predictions.data, 1)[1] # 对于任意一行（一个样本）的输出值的第1个维度，求最大，得到每一行的最大元素的下标\n",
    "    rights = pred.eq(labels.data).sum() #将下标与labels中包含的类别进行比较，并累计得到比较正确的数量\n",
    "    return rights, len(labels) #返回正确的数量和这一次一共比较了多少元素"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练一个LSTM。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 定义一个LSTM，其中输入输出层的单元个数取决于每个变量的类型取值范围\n",
    "lstm = LSTMNetwork(89 + 128 + 12, 128, 89 + 128 + 12)\n",
    "optimizer = optim.Adam(lstm.parameters(), lr=0.001)\n",
    "num_epochs = 100\n",
    "train_losses = []\n",
    "valid_losses = []\n",
    "records = []\n",
    "\n",
    "# 开始训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = []\n",
    "    # 开始遍历加载器中的数据\n",
    "    for batch, data in enumerate(train_loader):\n",
    "        # batch为数字，表示已经进行了第几个batch了\n",
    "        # data为一个二元组，分别存储了一条数据记录的输入和标签\n",
    "        # 每个数据的第一个维度都是batch_size = 30的数组\n",
    "        \n",
    "        lstm.train() # 标志LSTM当前处于训练阶段，Dropout开始起作用\n",
    "        init_hidden = lstm.initHidden(len(data[0])) # 初始化LSTM的隐单元变量\n",
    "        optimizer.zero_grad()\n",
    "#         print(data[0].size())\n",
    "#         print(data[1])\n",
    "#         print(data[1].size())\n",
    "        x, y = data[0].clone().detach().requires_grad_(True), data[1].clone().detach() # 从数据中提炼出输入和输出对\n",
    "        outputs = lstm(x, init_hidden) #喂入LSTM，产生输出outputs\n",
    "#         print(outputs[1].size())\n",
    "#         print(outputs[0].size())\n",
    "#         print(outputs[2].size())\n",
    "        \n",
    "        loss = criterion(outputs, y) #代入损失函数并产生loss\n",
    "#         print(loss.data.numpy())\n",
    "        train_loss.append(loss.data.numpy()) # 记录loss\n",
    "        loss.backward() #反向传播\n",
    "        optimizer.step() #梯度更新\n",
    "    if 0 == 0:\n",
    "        #在校验集上跑一遍，并计算在校验集上的分类准确率\n",
    "        valid_loss = []\n",
    "        lstm.eval() #将模型标志为测试状态，关闭dropout的作用\n",
    "        rights = []\n",
    "        # 遍历加载器加载进来的每一个元素\n",
    "        for batch, data in enumerate(valid_loader):\n",
    "            init_hidden = lstm.initHidden(len(data[0]))\n",
    "            #完成LSTM的计算\n",
    "            x, y = data[0].clone().detach().requires_grad_(True), data[1].clone().detach()\n",
    "            #x的尺寸：batch_size, length_sequence, input_size\n",
    "            #y的尺寸：batch_size, (data_dimension1=89+ data_dimension2=128+ data_dimension3=12)\n",
    "            outputs = lstm(x, init_hidden)\n",
    "            #outputs: (batch_size*89, batch_size*128, batch_size*11)\n",
    "            loss = criterion(outputs, y)\n",
    "            valid_loss.append(loss.data.numpy())\n",
    "            #计算每个指标的分类准确度\n",
    "            right1 = rightness(outputs[0], y[:, 0])\n",
    "            right2 = rightness(outputs[1], y[:, 1])\n",
    "            right3 = rightness(outputs[2], y[:, 2])\n",
    "            rights.append((right1[0] + right2[0] + right3[0]).numpy() * 1.0 / (right1[1] + right2[1] + right3[1]))\n",
    "        # 打印结果\n",
    "        print('第{}轮, 训练Loss:{:.2f}, 校验Loss:{:.2f}, 校验准确度:{:.2f}'.format(epoch, \n",
    "                                                                    np.mean(train_loss),\n",
    "                                                                    np.mean(valid_loss),\n",
    "                                                                    np.mean(rights)\n",
    "                                                                  ))\n",
    "        records.append([np.mean(train_loss), np.mean(valid_loss), np.mean(rights)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 绘制训练过程中的Loss曲线\n",
    "a = [i[0] for i in records]\n",
    "b = [i[1] for i in records]\n",
    "c = [i[2] * 10 for i in records]\n",
    "plt.plot(a, '-', label = 'Train Loss')\n",
    "plt.plot(b, '-', label = 'Validation Loss')\n",
    "plt.plot(c, '-', label = '10 * Accuracy')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三、音乐生成\n",
    "\n",
    "我们运用训练好的LSTM来生成音符。首先把seed喂给LSTM并产生第n_prev + 1个msg，然后把这个msg加到输入数据的最后面，删除第一个元素\n",
    "\n",
    "这就又构成了一个标准的输入序列；然后再得到下一个msg，……，如此循环往复得到音符序列的生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成3000步\n",
    "predict_steps = 3000\n",
    "\n",
    "# 初始时刻，将seed（一段种子音符，即我为开始读入的音乐文件）付给x\n",
    "x = seed\n",
    "# 将数据扩充为合适的形式\n",
    "x = np.expand_dims(x, axis = 0)\n",
    "# 现在的x的尺寸为：batch=1, time_step =30, data_dim = 229\n",
    "\n",
    "lstm.eval()\n",
    "initi = lstm.initHidden(1)\n",
    "predictions = []\n",
    "# 开始每一步的迭代\n",
    "for i in range(predict_steps):\n",
    "    # 根据前n_prev预测后面的一个音符\n",
    "    xx = torch.tensor(np.array(x, dtype = float),dtype = torch.float, requires_grad = True)\n",
    "    preds = lstm(xx, initi)\n",
    "    \n",
    "    # 返回预测的note，velocity，time的模型预测概率对数\n",
    "    a,b,c = preds\n",
    "    # a的尺寸为：batch=1*data_dim=89, b为1*128，c为1*11\n",
    "    \n",
    "    # 将概率对数转化为随机的选择\n",
    "    ind1 = torch.multinomial(a.view(-1).exp(), num_samples = 1) \n",
    "    ind2 = torch.multinomial(b.view(-1).exp(), num_samples = 1) \n",
    "    ind3 = torch.multinomial(c.view(-1).exp(), num_samples = 1) \n",
    "\n",
    "    ind1 = ind1.data.numpy()[0] # 0-89中的整数\n",
    "    ind2 = ind2.data.numpy()[0] # 0-128中的整数\n",
    "    ind3 = ind3.data.numpy()[0] # 0-11中的整数\n",
    "    \n",
    "    # 将选择转换为正确的音符等数值，注意time分为11类，第一类为0这个特殊的类，其余按照区间放回去\n",
    "    note = [ind1 + 24, ind2, 0 if ind3 ==0 else ind3 * interval + min_t]\n",
    "    \n",
    "    # 将预测的内容存储下来\n",
    "    predictions.append(note)\n",
    "    \n",
    "    # 将新的预测内容再次转变为输入数据准备喂给LSTM\n",
    "    slot = np.zeros(89 + 128 + 12, dtype = int)\n",
    "    slot[ind1] = 1\n",
    "    slot[89 + ind2] = 1\n",
    "    slot[89 + 128 + ind3] = 1\n",
    "    slot1 = np.expand_dims(slot, axis = 0)\n",
    "    slot1 = np.expand_dims(slot1, axis = 0)\n",
    "    \n",
    "    #slot1的数据格式为：batch=1*time=1*data_dim=229\n",
    "    \n",
    "    # x拼接上新的数据\n",
    "    x = np.concatenate((x, slot1), 1)\n",
    "    # 现在x的尺寸为: batch_size = 1 * time_step = 31 * data_dim =229\n",
    "    \n",
    "    # 滑动窗口往前平移一次\n",
    "    x = x[:, 1:, :]\n",
    "    # 现在x的尺寸为：batch_size = 1 * time_step = 30 * data_dim = 229\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将生成的序列转化为MIDI的消息，并保存MIDI音乐\n",
    "mid = MidiFile()\n",
    "track = MidiTrack()\n",
    "mid.tracks.append(track)\n",
    "\n",
    "for i, note in enumerate(predictions):\n",
    "    # 在note一开始插入一个147表示打开note_on\n",
    "    note = np.insert(note, 0, 147)\n",
    "    # 将整数转化为字节\n",
    "    bytes = note.astype(int)\n",
    "    # 创建一个message\n",
    "    msg = Message.from_bytes(bytes[0:3]) \n",
    "    # 0.001025为任意取值，可以调节音乐的速度。由于生成的time都是一系列的间隔时间，转化为msg后时间尺度过小，因此需要调节放大\n",
    "    time = int(note[3]/0.001025)\n",
    "    msg.time = time\n",
    "    # 将message添加到音轨中\n",
    "    track.append(msg)\n",
    "\n",
    "#保存文件\n",
    "mid.save('music/new_song.mid')\n",
    "###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
